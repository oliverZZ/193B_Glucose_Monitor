{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Infection_Detection_2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "p4JBCoaARlth"
      ],
      "machine_shape": "hm",
      "mount_file_id": "1fVZKc9C4FykUPjqTtt2lDlt_M0Km5RVd",
      "authorship_tag": "ABX9TyOEUgUeaDzQm2hhA0T9xaJi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oliverZZ/193B_Glucose_Monitor/blob/master/Infection_Detection_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_u9U5GsRKKnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "import pandas as pd\n",
        "pd.options.display.max_rows = 20\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "bg = pd.read_excel('/content/drive/My Drive/EEC 193/EEC 193B/Burn_Glucose_022020.xlsx', skiprows = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXcQ0KMM_hzw",
        "colab_type": "code",
        "outputId": "2ac5b0aa-a3d1-4daa-d492-34430c42c68b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        }
      },
      "source": [
        "bg"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PER_CODE</th>\n",
              "      <th>Collection Date</th>\n",
              "      <th>Time Vitals</th>\n",
              "      <th>Systolic</th>\n",
              "      <th>Diastolic</th>\n",
              "      <th>MAP</th>\n",
              "      <th>HR</th>\n",
              "      <th>RR</th>\n",
              "      <th>Temp</th>\n",
              "      <th>CVP</th>\n",
              "      <th>GCS</th>\n",
              "      <th>Vent</th>\n",
              "      <th>Time_CBC</th>\n",
              "      <th>WBC</th>\n",
              "      <th>Hgb</th>\n",
              "      <th>Hct</th>\n",
              "      <th>Platelet</th>\n",
              "      <th>Time Labs</th>\n",
              "      <th>Na</th>\n",
              "      <th>K_pos</th>\n",
              "      <th>BUN</th>\n",
              "      <th>Creatnine</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>Tbili</th>\n",
              "      <th>Chloride</th>\n",
              "      <th>V_CO2</th>\n",
              "      <th>PaO2</th>\n",
              "      <th>FIO2</th>\n",
              "      <th>PaCO2</th>\n",
              "      <th>HCO3</th>\n",
              "      <th>PH</th>\n",
              "      <th>Sepsis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21</td>\n",
              "      <td>2011-01-02</td>\n",
              "      <td>614.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>No</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.9</td>\n",
              "      <td>8.1</td>\n",
              "      <td>24.5</td>\n",
              "      <td>578.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.53</td>\n",
              "      <td>110.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>101.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>2011-01-03</td>\n",
              "      <td>600.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>37.3</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>No</td>\n",
              "      <td>59.0</td>\n",
              "      <td>7.8</td>\n",
              "      <td>7.9</td>\n",
              "      <td>25.1</td>\n",
              "      <td>615.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>3.7</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.55</td>\n",
              "      <td>130.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>104.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21</td>\n",
              "      <td>2011-01-04</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>37.5</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>No</td>\n",
              "      <td>208.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>8.7</td>\n",
              "      <td>26.6</td>\n",
              "      <td>607.0</td>\n",
              "      <td>208.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.53</td>\n",
              "      <td>172.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>103.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21</td>\n",
              "      <td>2011-01-05</td>\n",
              "      <td>930.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>37.5</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>No</td>\n",
              "      <td>103.0</td>\n",
              "      <td>9.3</td>\n",
              "      <td>8.4</td>\n",
              "      <td>25.7</td>\n",
              "      <td>414.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>4.8</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.49</td>\n",
              "      <td>150.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>103.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21</td>\n",
              "      <td>2011-01-06</td>\n",
              "      <td>1130.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>No</td>\n",
              "      <td>130.0</td>\n",
              "      <td>8.4</td>\n",
              "      <td>8.9</td>\n",
              "      <td>27.7</td>\n",
              "      <td>701.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.51</td>\n",
              "      <td>109.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>103.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6536</th>\n",
              "      <td>PCR-004-00018</td>\n",
              "      <td>2013-05-27</td>\n",
              "      <td>600.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>38.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>211.0</td>\n",
              "      <td>17.6</td>\n",
              "      <td>9.2</td>\n",
              "      <td>26.8</td>\n",
              "      <td>454.0</td>\n",
              "      <td>211.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.88</td>\n",
              "      <td>139.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>103.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6537</th>\n",
              "      <td>PCR-004-00018</td>\n",
              "      <td>2013-05-28</td>\n",
              "      <td>600.0</td>\n",
              "      <td>158.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>37.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6538</th>\n",
              "      <td>PCR-004-00018</td>\n",
              "      <td>2013-05-29</td>\n",
              "      <td>600.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>38.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6539</th>\n",
              "      <td>PCR-004-00018</td>\n",
              "      <td>2013-05-30</td>\n",
              "      <td>600.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>38.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6540</th>\n",
              "      <td>PCR-004-00018</td>\n",
              "      <td>2013-05-31</td>\n",
              "      <td>600.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>38.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6541 rows Ã— 32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           PER_CODE Collection Date  Time Vitals  ...  HCO3   PH  Sepsis\n",
              "0                21      2011-01-02        614.0  ...   NaN  NaN       0\n",
              "1                21      2011-01-03        600.0  ...   NaN  NaN       0\n",
              "2                21      2011-01-04       1000.0  ...   NaN  NaN       0\n",
              "3                21      2011-01-05        930.0  ...   NaN  NaN       0\n",
              "4                21      2011-01-06       1130.0  ...   NaN  NaN       0\n",
              "...             ...             ...          ...  ...   ...  ...     ...\n",
              "6536  PCR-004-00018      2013-05-27        600.0  ...   NaN  NaN       0\n",
              "6537  PCR-004-00018      2013-05-28        600.0  ...   NaN  NaN       0\n",
              "6538  PCR-004-00018      2013-05-29        600.0  ...   NaN  NaN       0\n",
              "6539  PCR-004-00018      2013-05-30        600.0  ...   NaN  NaN       0\n",
              "6540  PCR-004-00018      2013-05-31        600.0  ...   NaN  NaN       0\n",
              "\n",
              "[6541 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dib_zUIG_2D-",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing ##\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Vh2nuez_teH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Drop_nan_row(df):\n",
        "  \n",
        "  drop_idx = []\n",
        "  for i in range(len(df)):\n",
        "    nan_count = 0\n",
        "    for x in df.loc[i]:\n",
        "      if str(x) == 'nan':\n",
        "        nan_count += 1\n",
        "    if nan_count >= 15:\n",
        "      drop_idx.append(i)\n",
        "    \n",
        "  modified_df = df.drop(df.index[drop_idx], errors = 'ignore')\n",
        "  modified_df = modified_df.reset_index(drop = True)\n",
        "\n",
        "  return modified_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07tBdERtAkMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Drop_unrelated_cols(df):\n",
        "  df = df.drop(columns = ['PER_CODE', 'Collection Date', 'Time Vitals', 'Time Labs', 'Time_CBC', 'Vent'], errors = 'ignore')\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AV5WZumAoZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Drop_nan_col(df):\n",
        "  \n",
        "  num_rows = len(df)\n",
        "  for x in df:\n",
        "    num_nan = 0\n",
        "    for i in df[x]:\n",
        "      if str(i) == 'nan':\n",
        "        num_nan += 1\n",
        "    \n",
        "    if (num_nan/num_rows) >= 0.2:\n",
        "      df = df.drop(columns = x, errors = 'ignore')\n",
        "  \n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LScRw4gWAt7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Complete_dataset(df):\n",
        "\n",
        "  # Change \"Yes\" and \"No\" under \"Vent\" to 1 and 0\n",
        "  df = df.replace('No', 0)\n",
        "  df = df.replace('Yes', 1)\n",
        "\n",
        "  # drop nan or replace them with other value\n",
        "  df = df.dropna()\n",
        "  df = df.reset_index(drop = True)\n",
        "\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h75yiEpAABp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_preprocess(df):\n",
        "\n",
        "  # drop rows that have too many nan\n",
        "  df = Drop_nan_row(df)\n",
        "  # drop times and patient ids\n",
        "  df = Drop_unrelated_cols(df)\n",
        "  # drop cols that have too many nan\n",
        "  df = Drop_nan_col(df)\n",
        "  # Replace all the other nans\n",
        "  df = Complete_dataset(df)\n",
        "\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypWsMIYjAwwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bg = data_preprocess(bg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roPBfZ_UAyIB",
        "colab_type": "text"
      },
      "source": [
        "## Finding Score ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSbk_nS5A2xr",
        "colab_type": "code",
        "outputId": "35438158-0fe4-4195-cd82-6866c082a184",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "pip install -U imbalanced-learn"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: imbalanced-learn in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.22 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.22.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS_iV-PcA6Ac",
        "colab_type": "code",
        "outputId": "470d0ac1-4e0e-454c-9e79-3890b61d876e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import imblearn"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHlMA0GJLGZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def Scores_calculation(train_x, train_y, test_x, test_y):\n",
        "#   precision_scores = [[],[]]\n",
        "#   recall_scores = [[],[]]\n",
        "#   f1_score_scores = [[],[]]\n",
        "\n",
        "#   model = RandomForestClassifier()\n",
        "#   for i in range(0,10):\n",
        "#     model.fit(train_x, train_y)\n",
        "#     predictions = model.predict(test_x)\n",
        "#     report = classification_report(test_y, predictions, output_dict = True)\n",
        "\n",
        "#     precision_scores[0].append(report['0']['precision'])\n",
        "#     recall_scores[0].append(report['0']['recall'])\n",
        "#     f1_score_scores[0].append(report['0']['f1-score'])\n",
        "    \n",
        "#     precision_scores[1].append(report['1']['precision'])\n",
        "#     recall_scores[1].append(report['1']['recall'])\n",
        "#     f1_score_scores[1].append(report['1']['f1-score'])\n",
        "\n",
        "#   precision_scores_avg_0 = sum(precision_scores[0]) / 10\n",
        "#   recall_scores_avg_0 = sum(recall_scores[0]) / 10\n",
        "#   f1_score_scores_avg_0 = sum(f1_score_scores[0]) / 10\n",
        "\n",
        "#   precision_scores_avg_1 = sum(precision_scores[1]) / 10\n",
        "#   recall_scores_avg_1 = sum(recall_scores[1]) / 10\n",
        "#   f1_score_scores_avg_1 = sum(f1_score_scores[1]) / 10\n",
        "\n",
        "#   # print('0 precision average', precision_scores_avg_0)\n",
        "#   # print('1 precision average', precision_scores_avg_1)\n",
        "#   # print('0 recall average', recall_scores_avg_0)\n",
        "#   # print('1 recall average', recall_scores_avg_1)\n",
        "#   # print('0 f1_socre average', f1_score_scores_avg_0)\n",
        "#   # print('1 f1_socre average', f1_score_scores_avg_1)\n",
        "#   # print('average f1_scores', (f1_score_scores_avg_0 + f1_score_scores_avg_1)/2)\n",
        "\n",
        "#   return (f1_score_scores_avg_0 + f1_score_scores_avg_1)/2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4JBCoaARlth",
        "colab_type": "text"
      },
      "source": [
        "## Getting Best Model ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOyjCFacIbk1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = RandomForestClassifier()\n",
        "# x = bg[['RR', 'WBC', 'Glucose', 'Platelet']].values\n",
        "# y = bg['Sepsis'].values\n",
        "\n",
        "# train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axiWwHG_HSkQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ratio = 0.2\n",
        "\n",
        "# n_not_infected = len(train_y[train_y == 0])\n",
        "# n_new_ratio = int(n_not_infected * ratio)\n",
        "\n",
        "# for i in range(0, 9):\n",
        "#   ratio = round(ratio,1)\n",
        "#   print('ratio =', ratio, ':')\n",
        "\n",
        "#   if n_new_ratio > len(train_y[train_y == 1]):\n",
        "#         n_infected = n_new_ratio\n",
        "#   else:\n",
        "#         n_infected = len(train_y[train_y == 1])\n",
        "  \n",
        "#   sampling_numbers = {0: n_not_infected, 1: n_infected}\n",
        "\n",
        "#   smote = imblearn.over_sampling.SMOTE(sampling_strategy=sampling_numbers)\n",
        "#   train_x_smote, train_y_smote = smote.fit_resample(train_x, train_y)\n",
        "#   train_y_smote = pd.Series(train_y_smote)\n",
        "\n",
        "#   print(\"SMOTE:\")\n",
        "#   Scores_calculation(train_x_smote, train_y_smote, test_x, test_y)\n",
        "\n",
        "#   ros = imblearn.over_sampling.RandomOverSampler(sampling_strategy=sampling_numbers)\n",
        "#   train_x_ros, train_y_ros = ros.fit_resample(train_x, train_y)\n",
        "#   train_y_ros = pd.Series(train_y_ros)\n",
        "  \n",
        "#   print(\"ROS:\")\n",
        "#   Scores_calculation(train_x_ros, train_y_ros, test_x, test_y)\n",
        "\n",
        "#   ratios_and_multipliers = {.2: 5, .3: 3.3, .4: 2.5, .5: 2, .6: 1.6, .7: 1.4, .8: 1.2, .9: 1.1, 1.0: 1}\n",
        "\n",
        "#   n_minority = len(train_y[train_y == 1])\n",
        "#   n_majority = int(n_minority * ratios_and_multipliers[ratio])\n",
        "#   sampling_numbers = {0: n_majority, 1: n_minority}\n",
        "  \n",
        "#   rus = imblearn.under_sampling.RandomUnderSampler(sampling_strategy=sampling_numbers)\n",
        "#   train_x_rus, train_y_rus = rus.fit_resample(train_x, train_y)\n",
        "#   train_y_rus = pd.Series(train_y_rus)\n",
        "  \n",
        "#   print(\"RUS:\")\n",
        "#   Scores_calculation(train_x_rus, train_y_rus, test_x, test_y)\n",
        "#   print('\\n')\n",
        "\n",
        "#   ratio += 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQs5xOw7BGiY",
        "colab_type": "text"
      },
      "source": [
        "F1_score reaches its highest (average is about 0.599) when the imbalance mathod is RUS and the ratio is 0.4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHwSIFAhBcm_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import itertools\n",
        "\n",
        "# model = RandomForestClassifier()\n",
        "# # x = bg[['RR', 'WBC', 'Glucose', 'Platelet']].values\n",
        "# y = bg['Sepsis'].values\n",
        "\n",
        "# score = 0\n",
        "# comb = []\n",
        "\n",
        "# name_cols = list(bg.columns)\n",
        "# for subset in itertools.combinations(name_cols[0:-2], 5):\n",
        "#   x = bg[list(subset)].values\n",
        "#   train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=0)\n",
        "\n",
        "#   n_minority = len(train_y[train_y == 1])\n",
        "#   n_majority = int(n_minority * 2.5)\n",
        "#   sampling_numbers = {0: n_majority, 1: n_minority}\n",
        "  \n",
        "#   rus = imblearn.under_sampling.RandomUnderSampler(sampling_strategy=sampling_numbers)\n",
        "#   train_x_rus, train_y_rus = rus.fit_resample(train_x, train_y)\n",
        "#   train_y_rus = pd.Series(train_y_rus)\n",
        "  \n",
        "#   temp = Scores_calculation(train_x_rus, train_y_rus, test_x, test_y)\n",
        "#   if (score < temp):\n",
        "#     score = temp\n",
        "#     comb = subset\n",
        "\n",
        "# print(score)\n",
        "# print(comb)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWdht1eIDezB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from pprint import pprint\n",
        "# from sklearn.feature_selection import chi2\n",
        "\n",
        "# columns_to_use = list(bg.columns[0:-2])\n",
        "# x = bg[columns_to_use].values\n",
        "# y = bg['Sepsis'].values\n",
        "# train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# chi2_vals, pvals = chi2(train_x, train_y)\n",
        "# cols_to_pvals = zip(pvals, columns_to_use)\n",
        "# cols_sorted = sorted(cols_to_pvals)\n",
        "\n",
        "# pprint(cols_sorted)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3qPm9yuRsdS",
        "colab_type": "text"
      },
      "source": [
        "## Getting Best Features ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkCz1NvJlgOd",
        "colab_type": "text"
      },
      "source": [
        "### Progressive Selection ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "viMlbAZ2QvL8",
        "colab": {}
      },
      "source": [
        "# model = RandomForestClassifier()\n",
        "# x = bg[['Hct', 'Platelet', 'WBC', 'Glucose']].values\n",
        "# y = bg['Sepsis'].values\n",
        "# train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# scaler = RobustScaler()\n",
        "# train_x = scaler.fit_transform(train_x)\n",
        "# test_x = scaler.transform(test_x)\n",
        "\n",
        "# n_minority = len(train_y[train_y == 1])\n",
        "# n_majority = int(n_minority * 2.5)\n",
        "# sampling_numbers = {0: n_majority, 1: n_minority}\n",
        "\n",
        "# rus = imblearn.under_sampling.RandomUnderSampler(sampling_strategy=sampling_numbers)\n",
        "# train_x_rus, train_y_rus = rus.fit_resample(train_x, train_y)\n",
        "# train_y_rus = pd.Series(train_y_rus)\n",
        "  \n",
        "# score = Scores_calculation(train_x_rus, train_y_rus, test_x, test_y)\n",
        "# print(score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9qrPzKWdIto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = RandomForestClassifier()\n",
        "# temp = list(bg.columns)\n",
        "# temp.remove('Hct')\n",
        "# temp.remove('Platelet')\n",
        "# temp.remove('WBC')\n",
        "# temp.remove('Sepsis')\n",
        "# temp.remove('Temp')\n",
        "# temp.remove('RR')\n",
        "# temp.remove('HR')\n",
        "# col_use = ['Hct', 'Platelet', 'WBC', 'Temp', 'RR', 'HR']\n",
        "\n",
        "# for f in temp:\n",
        "#   g = [f]\n",
        "#   g = col_use + g\n",
        "\n",
        "#   x = bg[g].values\n",
        "#   y = bg['Sepsis'].values\n",
        "#   train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=0)\n",
        "\n",
        "#   scaler = RobustScaler()\n",
        "#   train_x = scaler.fit_transform(train_x)\n",
        "#   test_x = scaler.transform(test_x)\n",
        "\n",
        "#   n_minority = len(train_y[train_y == 1])\n",
        "#   n_majority = int(n_minority * 2.5)\n",
        "#   sampling_numbers = {0: n_majority, 1: n_minority}\n",
        "\n",
        "#   rus = imblearn.under_sampling.RandomUnderSampler(sampling_strategy=sampling_numbers)\n",
        "#   train_x_rus, train_y_rus = rus.fit_resample(train_x, train_y)\n",
        "#   train_y_rus = pd.Series(train_y_rus)\n",
        "  \n",
        "#   score = Scores_calculation(train_x_rus, train_y_rus, test_x, test_y)\n",
        "#   print(g,':',score)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuJxAe5aldKd",
        "colab_type": "text"
      },
      "source": [
        "Best feature combination: ['Hct', 'Platelet', 'WBC', 'Temp', 'RR', 'HR']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUXgJR7ilt0P",
        "colab_type": "text"
      },
      "source": [
        "### Regressive Selection ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsjxABy-lx8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.feature_selection import RFE\n",
        "\n",
        "# col = list(bg.columns)\n",
        "# col.remove('Sepsis')\n",
        "# x = bg[col].values\n",
        "# y = bg['Sepsis'].values\n",
        "# train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# scaler = RobustScaler()\n",
        "# train_x = scaler.fit_transform(train_x)\n",
        "# test_x = scaler.transform(test_x)\n",
        "\n",
        "# n_minority = len(train_y[train_y == 1])\n",
        "# n_majority = int(n_minority * 2.5)\n",
        "# sampling_numbers = {0: n_majority, 1: n_minority}\n",
        "\n",
        "# rus = imblearn.under_sampling.RandomUnderSampler(sampling_strategy=sampling_numbers)\n",
        "# train_x_rus, train_y_rus = rus.fit_resample(train_x, train_y)\n",
        "# train_y_rus = pd.Series(train_y_rus)\n",
        "\n",
        "# estimator = RandomForestClassifier()\n",
        "# selector = RFE(estimator, 3, step=1)\n",
        "# selector = selector.fit(train_x_rus, train_y_rus)\n",
        "\n",
        "# new_train_x = train_x[:, selector.support_]\n",
        "# new_test_x = test_x[:, selector.support_]\n",
        "\n",
        "# model = RandomForestClassifier()\n",
        "\n",
        "# f1_score_scores = [[],[]]\n",
        "\n",
        "# model = RandomForestClassifier()\n",
        "# for i in range(0,10):\n",
        "#   model.fit(new_train_x, train_y)\n",
        "#   predictions = model.predict(new_test_x)\n",
        "#   report = classification_report(test_y, predictions, output_dict = True)\n",
        "\n",
        "#   f1_score_scores[0].append(report['0']['f1-score'])\n",
        "#   f1_score_scores[1].append(report['1']['f1-score'])\n",
        "#   f1_score_scores_avg_0 = sum(f1_score_scores[0]) / 10\n",
        "#   f1_score_scores_avg_1 = sum(f1_score_scores[1]) / 10\n",
        "\n",
        "# print((f1_score_scores_avg_0 + f1_score_scores_avg_1)/2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vYmAFDP5wzC",
        "colab_type": "text"
      },
      "source": [
        "3 features: f1_score = 0.5483979297526201 \\\\\n",
        "4 features: f1_score = 0.5807557454179925 \\\\\n",
        "5 features: f1_score = 0.5788802053854059 \\\\\n",
        "6 features: f1_score = 0.5769307206585933 \\\\\n",
        "7 features: f1_score = 0.5722500953954065"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSgkYfshB9IU",
        "colab_type": "text"
      },
      "source": [
        "## Best features + Best Model ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p8yFCVyCDFV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "367846fd-fbda-47ba-ecca-683d0d4cd9ef"
      },
      "source": [
        "x = bg[['Hct', 'Platelet', 'WBC', 'Temp', 'RR', 'HR']].values\n",
        "y = bg['Sepsis'].values\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=0)\n",
        "\n",
        "scaler = RobustScaler()\n",
        "train_x = scaler.fit_transform(train_x)\n",
        "test_x = scaler.transform(test_x)\n",
        "\n",
        "n_minority = len(train_y[train_y == 1])\n",
        "n_majority = int(n_minority * 2.5)\n",
        "sampling_numbers = {0: n_majority, 1: n_minority}\n",
        "\n",
        "rus = imblearn.under_sampling.RandomUnderSampler(sampling_strategy=sampling_numbers)\n",
        "train_x_rus, train_y_rus = rus.fit_resample(train_x, train_y)\n",
        "train_y_rus = pd.Series(train_y_rus)\n",
        "\n",
        "f1_score_scores = [[],[]]\n",
        "sensitivity = []\n",
        "specificity = []\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "for i in range(0,10):\n",
        "  model.fit(train_x_rus, train_y_rus)\n",
        "  predictions = model.predict(test_x)\n",
        "  report = classification_report(test_y, predictions, output_dict = True)\n",
        "  ss = imblearn.metrics.sensitivity_specificity_support(test_y, predictions, average='macro')\n",
        "  \n",
        "  sensitivity.append(ss[0])\n",
        "  specificity.append(ss[1])\n",
        "\n",
        "  f1_score_scores[0].append(report['0']['f1-score'])\n",
        "  f1_score_scores[1].append(report['1']['f1-score'])\n",
        "\n",
        "f1_score_scores_avg_0 = sum(f1_score_scores[0]) / 10\n",
        "f1_score_scores_avg_1 = sum(f1_score_scores[1]) / 10\n",
        "sensitivity_avg = sum(sensitivity) / 10\n",
        "specificity_avg = sum(specificity) / 10\n",
        "\n",
        "print(\"f1 score = \", (f1_score_scores_avg_0 + f1_score_scores_avg_1)/2)\n",
        "print(\"sensitivity = \", sensitivity_avg)\n",
        "print(\"specificity = \", specificity_avg)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1 score =  0.6484801498567692\n",
            "sensitivity =  0.6329933966713833\n",
            "specificity =  0.6329933966713833\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr6qtsBvRk1u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "c5d6b5ee-666b-4d6b-d669-49cbde22c811"
      },
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "y_score = model.predict_proba(test_x)[:,1]\n",
        "false_positive_rate, true_positive_rate, threshold = roc_curve(test_y, y_score)\n",
        "print('roc_auc_score = ', roc_auc_score(test_y, y_score))\n",
        "\n",
        "plt.title('ROC Curve')\n",
        "plt.plot(false_positive_rate, true_positive_rate)\n",
        "plt.plot([0, 1], ls=\"--\")\n",
        "plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "roc_auc_score =  0.7304393234957213\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzFkiMMaYMGeJwBhjwpwlAmOMCXP/D7skRTiI0tfYAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olvxDwoDskQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}